{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input:\n",
    "- Question + <'pad'> + context\n",
    "\n",
    "Output:\n",
    "- The start index and end index of the extracted information from context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dataset = [\n",
    "    {\n",
    "        'context': 'My name is Thang and I am from Vietnam',\n",
    "        'question': 'What is my name?',\n",
    "        'answer': 'Thang'\n",
    "    },\n",
    "    {\n",
    "        'context': 'I love painting and my favorite artist is Vincent Van Gough',\n",
    "        'question': 'What is my favorite activity?',\n",
    "        'answer' : 'painting'\n",
    "    },\n",
    "    {\n",
    "        'context' : 'I am studying Computer Science at Nanyang Technological University',\n",
    "        'question' : 'What am I studying?',\n",
    "        'answer' : 'Computer Science'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'love', 'cats']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "text = 'I love cats'\n",
    "tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<cls>': 5,\n",
       " '<sep>': 4,\n",
       " 'vietnam<sep>what': 31,\n",
       " 'technological': 27,\n",
       " '<bos>': 2,\n",
       " '<unk>': 0,\n",
       " '?': 7,\n",
       " 'artist': 18,\n",
       " '<eos>': 3,\n",
       " '<pad>': 1,\n",
       " 'is': 6,\n",
       " 'my': 9,\n",
       " 'am': 8,\n",
       " '<cls>i': 10,\n",
       " 'name': 14,\n",
       " 'and': 11,\n",
       " 'favorite': 12,\n",
       " 'i': 13,\n",
       " 'studying': 15,\n",
       " 'nanyang': 24,\n",
       " '<cls>my': 16,\n",
       " 'activity': 17,\n",
       " 'at': 19,\n",
       " 'computer': 20,\n",
       " 'from': 21,\n",
       " 'gough<sep>what': 22,\n",
       " 'love': 23,\n",
       " 'painting': 25,\n",
       " 'science': 26,\n",
       " 'thang': 28,\n",
       " 'university<sep>what': 29,\n",
       " 'van': 30,\n",
       " 'vincent': 32}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def yield_tokens(data):\n",
    "    for item in data:\n",
    "        yield(tokenizer('<cls>' + item['context'] + '<sep>' + item['question']))\n",
    "\n",
    "#create vocab\n",
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(qa_dataset),\n",
    "    specials=['<unk>', '<pad>', '<bos>', '<eos>', '<sep>', '<cls>']\n",
    ")\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "vocab.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 1\n",
    "def pad_and_truncate(input_ids, max_seq_len):\n",
    "    if len(input_ids) > max_seq_len:\n",
    "        input_ids = input_ids[:max_seq_len]\n",
    "    elif len(input_ids) < max_seq_len:\n",
    "        input_ids += [PAD_IDX] * (max_seq_len - len(input_ids))\n",
    "\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 22\n",
    "def vectorize(question, context, answer, max_seq_len):\n",
    "    input_text = question + '<sep>' + context\n",
    "    input_ids = [vocab[token] for token in tokenizer(input_text)]\n",
    "    input_ids = pad_and_truncate(input_ids, MAX_SEQ_LENGTH)\n",
    "\n",
    "    answer_ids = [vocab[token] for token in tokenizer(answer)]\n",
    "    start_positions = input_ids.index(answer_ids[0])\n",
    "    end_positions = start_positions + len(answer_ids) - 1\n",
    "\n",
    "    input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
    "    start_positions = torch.tensor(start_positions, dtype=torch.long)\n",
    "    end_positions = torch.tensor(end_positions, dtype=torch.long)\n",
    "\n",
    "    return input_ids, start_positions, end_positions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(nn.Module):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        question_text = item['question']\n",
    "        context_text = item['context']\n",
    "        answer_text = item['answer']\n",
    "\n",
    "        input_ids, start_positions, end_positions = vectorize(\n",
    "            question_text, context_text, answer_text, 22\n",
    "        )\n",
    "\n",
    "        return input_ids, start_positions, end_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(input_ids):\n",
    "    return ' '.join([vocab.lookup_token(token) for token in input_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  8, 13, 15,  7,  0,  8, 15, 20, 26, 19, 24, 27,  0,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1],\n",
      "        [ 0,  6,  9, 14,  7,  0, 14,  6, 28, 11, 13,  8, 21,  0,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1]]) tensor([8, 8]) tensor([9, 8])\n",
      "tensor([[ 0,  6,  9, 12, 17,  7,  0, 23, 25, 11,  9, 12, 18,  6, 32, 30,  0,  1,\n",
      "          1,  1,  1,  1]]) tensor([8]) tensor([8])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = QADataset(qa_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "for batch in train_loader:\n",
    "    q, c, a = batch\n",
    "    print(q, c, a)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPostitionEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, max_length):\n",
    "        super().__init__()\n",
    "        self.word_embed = nn.Embedding(num_embeddings=vocab_size,\n",
    "                                       embedding_dim=embed_dim)\n",
    "        self.pos_embed = nn.Embedding(num_embeddings=max_length,\n",
    "                                      embedding_dim=embed_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        N, seq_len = x.size()\n",
    "        positions = torch.arange(0, seq_len).expand(N, seq_len)\n",
    "        output_1 = self.word_embed(x)\n",
    "        output_2 = self.pos_embed(positions)\n",
    "        output = output_1 + output_2\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, output_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=embed_dim,\n",
    "                                          num_heads=num_heads,\n",
    "                                          batch_first=True\n",
    "                                        )\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(in_features=embed_dim, out_features=ff_dim, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=ff_dim, out_features=embed_dim, bias=True)\n",
    "        )\n",
    "        self.layernorm1 = nn.LayerNorm(normalized_shape=embed_dim)\n",
    "        self.layernorm2 = nn.LayerNorm(normalized_shape=embed_dim)\n",
    "        self.dropout1 = nn.Dropout(p=dropout)\n",
    "        self.dropout2 = nn.Dropout(p=dropout)\n",
    "        self.linear_out = nn.Linear(in_features=embed_dim,\n",
    "                                    out_features=output_dim)\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        attn_output, _ = self.attn(query, key, value)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out_1 = self.layernorm1(query + attn_output)\n",
    "        ffn_out = self.ffn(out_1)\n",
    "        ffn_out = self.dropout2(ffn_out)\n",
    "        out_2 = self.layernorm2(ffn_out + out_1)\n",
    "        out_2 = self.linear_out(out_2)\n",
    "        return out_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransformerBlock(embed_dim=32, num_heads=1, ff_dim=128, output_dim=128)\n",
    "model(torch.randn(1, 32), torch.randn(1, 32), torch.randn(1, 32)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: transformer\n",
    "class QAModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 vocab_size, embedding_dim, n_heads,\n",
    "                 ff_dim, max_len):\n",
    "        super().__init__()\n",
    "        self.input_embedding = TokenAndPostitionEmbedding(\n",
    "            vocab_size, embedding_dim, max_len\n",
    "        )\n",
    "\n",
    "        self.transformer = TransformerBlock(embedding_dim, n_heads, ff_dim=64, output_dim=ff_dim)\n",
    "        self.start_linear = nn.Linear(ff_dim, 1)\n",
    "        self.end_linear = nn.Linear(ff_dim, 1)\n",
    "\n",
    "    def forward(self, text):\n",
    "        input_embedded = self.input_embedding(text)\n",
    "        transformer_out = self.transformer(input_embedded, input_embedded, input_embedded)\n",
    "        start_logits = self.start_linear(transformer_out).squeeze(-1)\n",
    "        end_logits = self.end_linear(transformer_out).squeeze(-1)\n",
    "        return start_logits, end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model parameters\n",
    "EMBEDDING_DIM = 32\n",
    "HIDDEN_SIZE = 128\n",
    "VOCAB_SIZE = len(vocab)\n",
    "N_HEADS = 1\n",
    "\n",
    "\n",
    "model = QAModel(\n",
    "    VOCAB_SIZE, EMBEDDING_DIM, N_HEADS, HIDDEN_SIZE, MAX_SEQ_LENGTH\n",
    ")\n",
    "\n",
    "input_context = torch.randint(0, 10, size=(1, 10))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    start_logits, end_logits = model(input_context)\n",
    "\n",
    "#print(start_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.281930923461914\n",
      "5.625787734985352\n",
      "5.431855201721191\n",
      "5.7655229568481445\n",
      "5.200865745544434\n",
      "4.5978851318359375\n",
      "4.624580383300781\n",
      "4.085083484649658\n",
      "4.106523513793945\n",
      "3.561677932739258\n",
      "3.59871768951416\n",
      "3.0926315784454346\n",
      "2.9918417930603027\n",
      "2.998030662536621\n",
      "2.657653331756592\n",
      "2.2859842777252197\n",
      "1.9957795143127441\n",
      "2.00809907913208\n",
      "1.5538716316223145\n",
      "1.5510176420211792\n",
      "1.3236503601074219\n",
      "0.7917777299880981\n",
      "0.7757298946380615\n",
      "1.1117939949035645\n",
      "0.7248416543006897\n",
      "0.5187174081802368\n",
      "0.5942517518997192\n",
      "0.22171202301979065\n",
      "0.41816240549087524\n",
      "0.20695018768310547\n",
      "0.17814938724040985\n",
      "0.4796469211578369\n",
      "0.27517473697662354\n",
      "0.12485484778881073\n",
      "0.18407566845417023\n",
      "0.0612393394112587\n",
      "0.12700507044792175\n",
      "0.044127076864242554\n",
      "0.12990613281726837\n",
      "0.02366236224770546\n"
     ]
    }
   ],
   "source": [
    "LR = 1e-3\n",
    "EPOCHS = 20\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=LR\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "for _ in range(EPOCHS):\n",
    "    for idx, (input_ids, start_positions, end_positions) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        start_logits, end_logits = model(input_ids)\n",
    "        start_loss = criterion(start_logits, start_positions)\n",
    "        end_loss = criterion(end_logits, end_positions)\n",
    "        loss = start_loss + end_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love painting and my favorite artist is Vincent Van Gough\n",
      "What is my favorite activity?\n",
      "i love\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample = qa_dataset[1]\n",
    "    context, question, answer = sample.values()\n",
    "    input_ids, start_position, end_position = vectorize(context, question, answer, MAX_SEQ_LENGTH)\n",
    "    input_ids = input_ids.unsqueeze(0)\n",
    "    start_logits, end_logits = model(input_ids)\n",
    "\n",
    "    offset = len(tokenizer(question)) + 2\n",
    "    start_position = torch.argmax(start_logits, dim=1).numpy()[0]\n",
    "    end_position = torch.argmax(end_logits, dim=1).numpy()[0]\n",
    "\n",
    "    start_position -= offset\n",
    "    end_position -= offset\n",
    "\n",
    "    start_position = max(start_position, 0)\n",
    "    end_position = min(end_position, len(tokenizer(context)) - 1)\n",
    "\n",
    "    if end_position >= start_position:\n",
    "        #extract the predicted answer span\n",
    "        context_tokens = tokenizer(context)\n",
    "        predicted_answer_tokens = context_tokens[start_position:end_position+1]\n",
    "        predicted_answer = ' '.join(predicted_answer_tokens)\n",
    "        print(context)\n",
    "        print(question)\n",
    "        print(predicted_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chắc thằng cu này đòi data lớn rồi :)) cay thật"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devinthang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
